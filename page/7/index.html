<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"gmrccc.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="GM兔的博客">
<meta property="og:type" content="website">
<meta property="og:title" content="GMR&#39;s Blog">
<meta property="og:url" content="http://gmrccc.com/page/7/index.html">
<meta property="og:site_name" content="GMR&#39;s Blog">
<meta property="og:description" content="GM兔的博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="GMRCCC">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://gmrccc.com/page/7/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/7/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>GMR's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">GMR's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="GMRCCC"
      src="/uploads/1.jpg">
  <p class="site-author-name" itemprop="name">GMRCCC</p>
  <div class="site-description" itemprop="description">GM兔的博客</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">158</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/GMRCCC" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;GMRCCC" rel="noopener me" target="_blank">GitHub</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.2%20%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.2%20%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">2.2 经典网络</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：14:37:51" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习4-卷积神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><p>LeNet-5可以识别图片中的手写数字，由于是针对灰度图像训练的，因此训练图片大小只有32×32×1</p>
<p><img src="/img/Pastedimage20231010162559.png" alt="图片"></p>
<ol>
<li>早期很喜欢用平均池化，但现在常用最大池化。</li>
<li>在最后一步，当时的LeNet-5用了另外一种分类器进行分类，但现在常用softmax进行分类。</li>
<li>这个神经网络只有大约60w个参数，而现在神经网络的参数可能有上亿个。</li>
</ol>
<p><img src="/img/Pastedimage20231010162936.png" alt="图片"></p>
<p>从这个神经网络，我们不难发现图片的长和宽呈下降趋势，而通道数呈上升趋势。</p>
<p>卷积-池化-卷积-池化-全连接-输出 是现在常用的一种神经网络模式。</p>
<p>在当时，人们很少用ReLU激活函数，而更常用sigmoid&#x2F;tanh函数。</p>
<p>由于当时计算多通道卷积很复杂，采用的做法常是让卷积核的通道数和图片的通道数相同，然后用很复杂的方法一一对应卷积，其中的很多细节现在可能都用不到了。</p>
<p>如果要读这篇经典文章，建议精读第二段，粗读第三段(第三段都是一些很有趣的实验结果)。</p>
<p><img src="/img/Pastedimage20231010163553.png" alt="图片"></p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>AlexNet有大约6000万个参数，非常擅长处理相似的图片，一大优势是使用了ReLU函数</p>
<p><img src="/img/Pastedimage20231010165048.png" alt="图片"></p>
<ol>
<li>当时的GPU速度还很慢，AlexNet采用了非常复杂的方法在两个GPU上训练，基本思路是将各个层拆成两半分别学习，然后用特殊方法在两个GPU之间沟通。</li>
<li>使用了局部响应归一化层(LRN层，现在很少用)，大致思路是在图片中开辟一个”信道”，这样可以只用较少的激活单元读到所有的参数。</li>
</ol>
<p><img src="/img/Pastedimage20231010165607.png" alt="图片"></p>
<h3 id="VGG-16"><a href="#VGG-16" class="headerlink" title="VGG-16"></a>VGG-16</h3><p>VGG16简化了神经网络结构，用了大量的卷积层，16的意思是用了16个卷积层和全连接层。</p>
<p><img src="/img/Pastedimage20231010170150.png" alt="图片"></p>
<p>通道数非常规整地一直翻倍，图片大小也非常规整地一直减半，这种规整导致很多深度学习研究者很推崇这个模型，这意味着图片大小的缩小和通道数的增多很可能是 <strong>有规律的</strong> 。</p>
<p>缺点是参数太多，有1亿多个参数。</p>
<p><img src="/img/Pastedimage20231010170710.png" alt="图片"></p>
<p>如果要阅读这些论文，建议先读AlexNet，然后读VGG，最后读LeNet，这对了解网络结构很有帮助。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.3%20%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.3%20%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">2.3 残差网络</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：14:39:08" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习4-卷积神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>非常深的神经网络很难训练，因为存在梯度消失和梯度爆炸的问题。</p>
<p>远跳连接可以从某一层获得激活，然后迅速反馈给另外一层(甚至是深层)。可以用远跳连接构建能训练深度网络的ResNet(甚至超过100层)。</p>
<p>ResNet由残差块组成。</p>
<p>从a[l]到a[l+2]通常要经过两层信息传播，但通过远跳连接可以让a[l+2]直接收到a[l]的信息</p>
<p><img src="/img/Pastedimage20231011103107.png" alt="图片"></p>
<p>这样一个块称为残差块，残差块的堆叠能形成更深的神经网络</p>
<p><img src="/img/Pastedimage20231011103523.png" alt="图片"></p>
<p>如图，每两层使用一次远跳连接，每个远跳连接之间称为一个残差块，整个网络称为残差网络(其他网络叫普通网络 Plain，由何凯明在其论文中区分)。</p>
<p>如果用标准优化算法训练普通网络，理论上讲，随着网络深度的增加，训练错误率应该越来越低</p>
<p><img src="/img/Pastedimage20231011104303.png" alt="图片"></p>
<p>但实际上，随着深度的增加，普通网络会变得越来越难训练，在某个节点后错误率会不降反增。</p>
<p>使用残差网络则不会出现这个问题，它可以用来训练非常深的网络(有人甚至在1000层上做了实验)</p>
<p><img src="/img/Pastedimage20231011105012.png" alt="图片"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.4%20%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.4%20%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E7%94%A8/" class="post-title-link" itemprop="url">2.4 残差网络为什么有用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：14:41:54" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习4-卷积神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>上一节我们了解到，更深的神经网络可能会减弱在训练集上训练的效率，这也是我们不愿意训练更深网络的原因。但残差网络减弱甚至避免了这个问题</p>
<p><img src="/img/Pastedimage20231011110353.png" alt="图片"></p>
<p>假设你训练了一个很大的神经网络，现在你希望这个网络更深，于是你在后面加了一个残差块。</p>
<p>则a[l+2] &#x3D; g(z[l+2]+a[l]) &#x3D; g(W[l+2]a[l+1] + b[l+2]+a[l])</p>
<p>如果在训练过程中权重W变为0(为了方便令b也为0)，则a[l+2]&#x3D;g(a[l])，由于大多数用的是ReLU激活函数，则a[l+2]&#x3D;a[l]。</p>
<p>举这个例子并不是说明一种特殊情况，而是想说在残差块中，a[l+2]想变为a[l]是非常容易的，因此残差块至少 <strong>不会使神经网络的训练效率变低</strong> ，这也是残差网络越来越深训练效率也不会下降的原因。</p>
<p>另外，如果要计算g(W[l+2]a[l+1] + b[l+2]+a[l])，则a[l]的维度要和a[l+2]相同，卷积核的same模式很好的帮助了这一点。</p>
<p>如果不用same卷积，也可以在a[l]前加一个权重Ws进行训练，使其维度相同。</p>
<p>核心思想是，残差块的输出值和残差块的输入值相等并不难，因此效率至少不会降低。如果使用普通网络，输出值和输入值相等的权重非常难调整。</p>
<p>最后来看残差网络进行图片识别的例子</p>
<p><img src="/img/Pastedimage20231011111450.png" alt="图片"></p>
<p>就是使用same卷积，每两层加一个远跳连接。在池化层部分多加Ws来保持相同维度。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.5%20%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BB%A5%E5%8F%8A1%C3%971%E5%8D%B7%E7%A7%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.5%20%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BB%A5%E5%8F%8A1%C3%971%E5%8D%B7%E7%A7%AF/" class="post-title-link" itemprop="url">2.5 网络中的网络以及1×1卷积</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：14:48:08" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习4-卷积神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>1×1卷积对单通道图片用处不大，只是单纯乘了一个数，没什么用</p>
<p><img src="/img/Pastedimage20231011140117.png" alt="图片"></p>
<p>对于多通道，我们可以把图片大小的某一个像素位置的多个通道看作一个”向量”(类比于神经网络)，则1×1卷积干的事情就相当于将这个”向量”输入到一个”输入单元”，然后输出值。如果有多个卷积核，相当于有多个输入单元</p>
<p><img src="/img/Pastedimage20231011140621.png" alt="图片"></p>
<p>这种方法称为1×1卷积或Network in Network，在很多地方都有应用。</p>
<p>1×1卷积的一个用处就是减少通道数，如果你有一个28×28×192的输入，那么你可以使用32个1×1×192的卷积核，将通道数量减少为32，保持长和宽不变。当然，保持通道数不变也是有用的，这相当于将原来的数进行了线性组合(加个ReLU就是非线性函数)，这对构建更复杂的函数映射很有帮助</p>
<p><img src="/img/Pastedimage20231011141536.png" alt="图片"></p>
<p>池化层用很简单的操作压缩了图像的长和宽，而1×1卷积则用简单的操作压缩图像的通道数。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.6%20%E8%B0%B7%E6%AD%8CInception%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.6%20%E8%B0%B7%E6%AD%8CInception%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B/" class="post-title-link" itemprop="url">2.6 谷歌Inception网络简介</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：15:07:57" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习4-卷积神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在构建网络时我们通常要自己决定卷积核的大小，而Inception网络则能让网络自己决定卷积核大小，虽然网络变得更复杂，但是效果很好。</p>
<p><img src="/img/Pastedimage20231011142757.png" alt="图片"></p>
<p>我们同时使用1×1、3×3、5×5的卷积和一个步幅为1的最大池化，全部采用same模式以保证输出的长宽保持一致，然后将结果纵向堆叠起来，形成一个28×28×256的输出。</p>
<p>这样神经网络就能自己学习参数来决定是否使用这几个卷积和池化中的一种或几种。</p>
<p>假设对一个28×28×192的输入图像做5×5的same卷积(卷积核32个)，则需要的运算次数为28×28×32×5×5×192约为120m次。</p>
<p>如果我们先做一个1×1的卷积将图像进行缩小，然后再放大呢？</p>
<p><img src="/img/Pastedimage20231011145357.png" alt="图片"></p>
<p>可以看到，此时只需要12.4m次运算，比原来缩小了10倍。1×1的卷积层通常被称为”瓶颈层”(bottleneck layer)。</p>
<p>Inception模块的主要思想就是，通过瓶颈层来大幅度缩小图像大小(只要选择的瓶颈层合理，模型的效果并不会下降)，从而减少计算成本。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.7%20Inception%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.7%20Inception%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">2.7 Inception网络</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：15:14:30" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习4-卷积神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>一个Inception模块</p>
<p><img src="/img/Pastedimage20231011150357.png" alt="图片"></p>
<p>和上一节提到的类似，我们使用1×1卷积来减少计算成本，注意最后一层最大池池化的过程，使用了padding让池化后的图像和池化前一致，由于池化无法改变通道数，额外用1×1卷积缩小了通道数量。</p>
<p><img src="/img/Pastedimage20231011151541.png" alt="图片"></p>
<p>Inception网络就是多个Inception模块的堆积。注意下面还带了几个尾巴，这些分支的作用是通过隐藏层希望能做出一些预测(全是softmax输出)，它确保了即使中间层对图片分类的预测也不算太坏，这对整个网络起了调整的效果，防止网络发生过拟合。</p>
<p>这个Inception由google创建，称为goolLeNet(向LeNet致敬)。</p>
<p>Inception(盗梦空间)这个名字的由来是盗梦空间中的一个梗</p>
<p><img src="/img/Pastedimage20231011152302.png" alt="图片"></p>
<p>表明了作者想建立更深层网络的决心。</p>
<p>Inception现在已经有了许多新的版本，甚至有些使用了远跳连接。但不管版本如何变化，基本思想都是对Inception模块的不断重复，因此只要理解了Inception模块，就能理解Inception网络。</p>
<p>个人理解：通过1×1卷积减少计算量，从而能构建更深层的网络。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.8%20%E4%BD%BF%E7%94%A8%E5%BC%80%E6%BA%90%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.8%20%E4%BD%BF%E7%94%A8%E5%BC%80%E6%BA%90%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88/" class="post-title-link" itemprop="url">2.8 使用开源的实现方案</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：15:15:13" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习4-卷积神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在观看论文时，从github上找别人已经复现的代码能大大加快你看论文的进度。</p>
<p>使用开源项目的好处是作者通常已经使用了庞大的数据集来预训练这个网络，因此当我们在这个项目的基础上构建自己网络时就可以通过迁移学习来使用他们预训练好的权重，从而加快自己模型的训练速度。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.9%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.9%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/" class="post-title-link" itemprop="url">2.9 迁移学习</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：15:16:25" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习4-卷积神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>比起随机初始化自己的权重，从github上找别人已经预训练好的权重(可能用了很多GPU花了好几个月进行训练)作为自己权重的初始化能够节省大量的时间。</p>
<p>假设你需要训练一个猫分类器，它需要识别Tigger、Misty或两者都不是三类，但你现有的数据集非常小不足以支持大型网络的训练。</p>
<p>这时候你从网上去寻找一个也是做分类的模型(它可能分1000个类，但没关系)，然后将这个模型的最后一层softmax去掉，换做自己的softmax层。</p>
<p>在训练过程中，将别人已经训练好的参数全部冻结(很多框架都有这个功能，trainableParameter&#x3D;0或者freeze&#x3D;1)，只训练最后的softmax层。</p>
<p>或者，直接用前面的网络计算出结果保存在磁盘中，然后拿这些结果直接对softmax层进行计算，这样就避免了每次迭代都需要重新计算前面层的麻烦</p>
<p><img src="/img/Pastedimage20231011155326.png" alt="图片"></p>
<p>如果你有更大的训练集怎么办？你可以只冻结前面几层，然后将后面的层重新初始化训练，或者将后面几层替换成你自己的模型重新训练</p>
<p><img src="/img/Pastedimage20231011160002.png" alt="图片"></p>
<p>规律就是，如果你拥有的数据集越多，那么你需要冻结的层数就越少，你能训练的层数也越多。当你有很多数据时，你可以不只训练softmax层，可以对一个中型的网络进行训练。</p>
<p>当你有大量数据时，你可以不冻结任何一层，将整个网络预训练的权重当做初始化权重，然后重新训练它</p>
<p><img src="/img/Pastedimage20231011160401.png" alt="图片"></p>
<p>由于计算机视觉领域在网上有很多别人已经训练好的模型，以及有很多公开的数据集，因此常见的做法是从网上下载别人的模型和权重当做初始化，然后用公开的数据集去继续训练它。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3.1%20%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3.1%20%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D/" class="post-title-link" itemprop="url">3.1 目标定位</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：15:32:21" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习4-卷积神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>和分类不同，对象定位需要在图片中定位一个物体，并用方框将其框起来，而对象检测则是利用分类和对象定位在一张图片中检测多个物体</p>
<p><img src="/img/Pastedimage20231012151309.png" alt="图片"></p>
<p>一般的分类问题通常用softmax输出四个值，假设我们需要检测路上的行人、车、摩托车和背景</p>
<p><img src="/img/Pastedimage20231012151959.png" alt="图片"></p>
<p>而为了实现目标定位，我们可以让神经网络多输出四个数，来表示预测框。</p>
<p>约定俗成的，我们让(0,0)表示一张图片的左上角，(1,1)表示一张图片的右下角，(bx,by)表示定位框的中心点，bw表示定位框的宽，bh表示定位框的高</p>
<p><img src="/img/Pastedimage20231012152449.png" alt="图片"></p>
<p>这样我们输出的yhat应该有八个参数，第一个参数Pc表示图片中是否有物体，1为有0没有；后面四个参数表示定位框的位置，最后三个参数表示三个类别(行人、车、摩托)中哪一个存在</p>
<p><img src="/img/Pastedimage20231012153412.png" alt="图片"></p>
<p>当Pc等于1时，我们才需要考虑后面的参数，当Pc等于0时，代表图片中没有物体，那么定位框参数和类别的参数就都没有意义，不需要关心了。</p>
<p>特别的，如果我们用平方损失函数来计算这个定位器的损失，那么只有当Pc&#x3D;1时，我们才需要对所有8个参数都计算损失，当Pc&#x3D;0时，我们就不需要关心其他的参数，只需关心输出的Pc和我们自己定的Pc的损失即可。</p>
<p>通常损失函数并没有这么简单，我们可能对c1、c2、c3使用对数损失函数，并用softmax输出一个值，对bx、by、bh、bw使用平方损失函数，对pc使用逻辑回归函数(或其他)。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3.10%20%E5%80%99%E9%80%89%E5%8C%BA%E5%9F%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/3.10%20%E5%80%99%E9%80%89%E5%8C%BA%E5%9F%9F/" class="post-title-link" itemprop="url">3.10 候选区域</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：16:10:57" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A04-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习4-卷积神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>用卷积实现滑动窗口有一个缺点，就是算法会在明显没有物体的区域去浪费时间。</p>
<p><img src="/img/Pastedimage20231013162719.png" alt="图片"></p>
<p>这篇论文介绍了一种RCNN算法(带区域的卷积神经网络)，这个算法尝试选出一些区域，在这些区域上运行卷积网络分类器是有意义的</p>
<p><img src="/img/Pastedimage20231013162712.png" alt="图片"></p>
<p>这样我们就不需要在所有窗口上跑算法，而是跑一部分就可以了。</p>
<p>选择候选区域的方法是用图像分割算法，图像分割结果如下</p>
<p><img src="/img/Pastedimage20231013163025.png" alt="图片"></p>
<p>分割算法就是先找出约2000个色块，然后给这2000个色块放置边界框，最后对这些色块跑一下分类器，这样能减少需要处理的位置从而减少卷积网络分类器需要的时间</p>
<p><img src="/img/Pastedimage20231013165110.png" alt="图片"></p>
<p>RCNN做的就是先选择几个候选区域，然后分辨候选区域中是否存在要辨别的物体，输出一个标签和一个精准的边界框(RCNN并不会直接拿色块边界当作自己的边界框，而是输出一个更加精确的)</p>
<p>但RCNN现在看来也不够快，所以有一系列工作去改进这个算法。</p>
<p>Fast-RCNN使用了卷积的滑动窗口来提高检测的速度(初版的RCNN是直接对各个候选区间进行分类的)，但缺点是得到候选区域的聚类步骤仍然非常缓慢。</p>
<p>Faster-RCNN使用更快的卷积神经网络而不是传统的分割算法来获取候选区域的色块，比Fast-RCNN快了很多。</p>
<p><img src="/img/Pastedimage20231013165916.png" alt="图片"></p>
<p>想了解更详细的，可以参考论文</p>
<p><img src="/img/Pastedimage20231013165936.png" alt="图片"></p>
<p>当然，即便是改进后的R-CNN，速度和YOLO相比还是有不少差距。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/6/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/8/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">GMRCCC</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
