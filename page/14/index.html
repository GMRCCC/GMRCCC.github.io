<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"gmrccc.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="GM兔的博客">
<meta property="og:type" content="website">
<meta property="og:title" content="GMR&#39;s Blog">
<meta property="og:url" content="http://gmrccc.com/page/14/index.html">
<meta property="og:site_name" content="GMR&#39;s Blog">
<meta property="og:description" content="GM兔的博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="GMRCCC">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://gmrccc.com/page/14/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/14/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>GMR's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">GMR's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="GMRCCC"
      src="/uploads/1.jpg">
  <p class="site-author-name" itemprop="name">GMRCCC</p>
  <div class="site-description" itemprop="description">GM兔的博客</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">158</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/GMRCCC" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;GMRCCC" rel="noopener me" target="_blank">GitHub</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.3%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.3%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">1.3 机器学习基础</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-26 00:00:00 / 修改时间：14:26:18" itemprop="dateCreated datePublished" datetime="2023-10-26T00:00:00+08:00">2023-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习2-改善深层神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>当算法的偏差很高时，我们需要调整模型来减小偏差。比如换一个更大的模型，训练更长时间等等。保证低偏差是模型训练的最低标准。</p>
<p>接下来考虑方差，我们用验证集去测试一个在训练集上结果理想的模型。如果方差高的话，我们可以通过添加数据来修正(但通常不会有新的数据)，或者采用正则化方法，有时也可以找一个新的模型，起到一箭双雕(同时低方差和低偏差)的作用。</p>
<p><img src="/img/Pastedimage20230904165607.png" alt="图片"></p>
<p>我们需要根据方差和偏差来选择不同的修正方法，比如如果偏差很高，那么准备更多的数据就没什么用。</p>
<p>在机器学习早期，调整方差和偏差往往会影响另一个数据的大小。但深度学习可以做到在降低其中一个的同时降低另外一个或者不影响另外一个，这也是深度学习如此重要且我们不需要太多关注平衡方差和偏差的重要原因。</p>
<p>比如训练一个更大的网络几乎没有负面影响，主要代价也就是时间(前提是网络是规范化的)。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.4%20%E6%AD%A3%E5%88%99%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.4%20%E6%AD%A3%E5%88%99%E5%8C%96/" class="post-title-link" itemprop="url">1.4 正则化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-26 00:00:00 / 修改时间：14:46:24" itemprop="dateCreated datePublished" datetime="2023-10-26T00:00:00+08:00">2023-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习2-改善深层神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>当你怀疑你的神经网络过拟合即方差比较高时，最先想到的方法可能是正则化。(另一个方法是准备更多的数据，但有时候可能没时间准备)</p>
<p>正则化有助于减少过拟合和网络误差。</p>
<p>L1正则和L2正则</p>
<p><img src="/img/Pastedimage20230905091254.png" alt="图片"></p>
<ol>
<li>由于w本身就包含了很多参数，因此加不加b都只是众多参数的一个，可以忽略不计。</li>
<li>L1正则的结果会导致w是一个稀疏矩阵(包含很多的0)。</li>
<li>人们越来越倾向使用L2正则。</li>
<li>λ是正则化参数，我们常使用验证集或交叉验证来配置这个参数。</li>
<li>正则化可以帮助设置w值变小，避免过拟合(w值过大曲线会变得很扭曲)</li>
<li>在python中，lambda是保留字段，因此我们通常用lambd来表示。</li>
</ol>
<p>正则化有时候也被称为 <strong>权重衰减</strong> ，相当于在原先w上乘了一个小于1的系数，会导致权重不断缩小</p>
<p><img src="/img/Pastedimage20230905093543.png" alt="图片"></p>
<p>正则主要用于W的更新，在损失函数中添加正则项，则在算dW时在后面会相应地多一个正则修正，注意此时的正则(图中紫色部分)已经是求导后的正则了。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.5%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AD%A3%E5%88%99%E5%8C%96%E5%8F%AF%E4%BB%A5%E5%87%8F%E5%B0%91%E8%BF%87%E6%8B%9F%E5%90%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.5%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AD%A3%E5%88%99%E5%8C%96%E5%8F%AF%E4%BB%A5%E5%87%8F%E5%B0%91%E8%BF%87%E6%8B%9F%E5%90%88/" class="post-title-link" itemprop="url">1.5 为什么正则化可以减少过拟合</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-26 00:00:00 / 修改时间：14:47:24" itemprop="dateCreated datePublished" datetime="2023-10-26T00:00:00+08:00">2023-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习2-改善深层神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>当正则化参数λ越大时，权重矩阵就越接近0.直观理解就是把多隐藏单元的权重设为0，消除这些隐藏单元的影响。神经网络就会慢慢简化为一个很小但是深度很大的网络。</p>
<p>当发生过拟合时，我们使用正则化，网络会慢慢简化从高方差慢慢变成高偏差，而在简化过程中λ存在一个中间值，同时有低方差和低偏差，这个值就是我们想要的</p>
<p><img src="/img/Pastedimage20230905104352.png" alt="图片"></p>
<p>其实正则化过程就是缩小W，从而让Z也变得更小，从而简化拟合曲线，正则化的过程会让一条过拟合的曲线慢慢简化为一条直线，而在这中间存在某种状态，它有着非常优美的曲线轨迹，又能较好的对结果进行预测。</p>
<p>从激活函数的方向来看，正则化让z变得更小接近0，如果用的是tanh激活，则在0附近的函数曲线呈线性，我们知道当激活函数为线性时，无论有多少层隐藏层，最终结果都是输入的线性组合，这会让网络变得更加简单，从而减少过拟合</p>
<p><img src="/img/Pastedimage20230905105514.png" alt="图片"></p>
<p>最后，我们在计算成本函数时加上L2正则，保证J在所有增幅范围内单调递减</p>
<p><img src="/img/Pastedimage20230905110307.png" alt="图片"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.7%20%E7%90%86%E8%A7%A3Dropout/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.7%20%E7%90%86%E8%A7%A3Dropout/" class="post-title-link" itemprop="url">1.7 理解Dropout</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-26 00:00:00 / 修改时间：15:00:03" itemprop="dateCreated datePublished" datetime="2023-10-26T00:00:00+08:00">2023-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习2-改善深层神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>dropout和L2正则类似，都是为了缩小权重。</p>
<p>我们考虑一个极端的例子，假设有四个神经元输入到一个神经元中</p>
<p><img src="/img/Pastedimage20230905143937.png" alt="图片"></p>
<p>由于前面四个神经元有可能会随机失活(dropout)，因此权重不会倾向于某个神经元，而是会均匀的在四个神经元上都增加一点权重，这会导致平方范数缩小，起到和L2正则类似的效果。</p>
<p>L2对不同权重的衰减是不同的，它取决于倍增的激活函数的大小，在某种程度上，dropout更适用于不同的输入范围。</p>
<p>我们可以根据层中神经元数来选择keep-prob值，如果神经元多的话，可以将keep-prob设置的低一些防止过拟合，如果神经元少的话甚至可以设置为1即不做dropout</p>
<p><img src="/img/Pastedimage20230905150539.png" alt="图片"></p>
<p>值得注意的是，dropout是防止神经网络过拟合的一种方法，因此除非算法过拟合，最好不要使用dropout，这也导致dropout在除CV之外的其他领域用的比较少。</p>
<p>dropout有个缺点是使成本函数不再被明确定义，因为优化了某些结点，导致成本函数很难去计算，这导致我们很难去判断成本函数是否在下降。</p>
<p>可以先关闭dropout，运行代码保证J单调递减，再打开dropout函数。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.8%20%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.8%20%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/" class="post-title-link" itemprop="url">1.8 其他正则化方法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-26 00:00:00 / 修改时间：15:02:43" itemprop="dateCreated datePublished" datetime="2023-10-26T00:00:00+08:00">2023-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习2-改善深层神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="数据增广"><a href="#数据增广" class="headerlink" title="数据增广"></a>数据增广</h3><p>当出现过拟合时，我们希望能够增加数据集，但是去收集新的图片又显得过于麻烦。</p>
<p>我们可以在原图片的基础上进行水平翻转、扭曲等操作来扩大我们的数据集，虽然没有新图片的效果好，但也有效，这种方法称为数据增广</p>
<p><img src="/img/Pastedimage20230905153253.png" alt="图片"></p>
<h3 id="early-stopping"><a href="#early-stopping" class="headerlink" title="early stopping"></a>early stopping</h3><p>当我们绘制误差时，我们可以把训练集和验证集的误差全部绘制出来，你可能会发现虽然训练集的误差一直在降，但验证集的误差在下降到某个点之后就开始上升了，我们可以在这个点提前停止训练，防止过拟合。</p>
<p>在训练过程中，权重W的值会越来越大，此时我们可以提前停止，使W的弗罗贝尼乌斯范数小一点。</p>
<p>early stopping的一个问题是不能同时处理减少成本函数和防止过拟合，如果过早停止那么成本函数就会上升，而如果训练时间过长又会出现过拟合现象</p>
<p><img src="/img/Pastedimage20230905155616.png" alt="图片"></p>
<p>另一种防止过拟合的方法就是前面介绍的L2正则，使用这种方法你可以尽情地训练你的网络，但缺点是你必须去尝试很多正则化参数λ的值，这也导致计算时间非常的长。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.6%20dropout%E6%AD%A3%E5%88%99/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.6%20dropout%E6%AD%A3%E5%88%99/" class="post-title-link" itemprop="url">1.6 dropout正则</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-26 00:00:00 / 修改时间：14:58:52" itemprop="dateCreated datePublished" datetime="2023-10-26T00:00:00+08:00">2023-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习2-改善深层神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>什么是dropout，如果在神经网络中存在过拟合， <strong>对每一个样本</strong> ，我们可以随机挑选50%的神经元失活来简化网络，这看起来有点怪，但确实有用</p>
<p><img src="/img/Pastedimage20230905111455.png" alt="图片"></p>
<p>最常用的是inverted dropout(反向随机失活)</p>
<p>首先要定义一个dropout向量，先要设置一个keep-prob，这里设置为0.8</p>
<p>对一个包含3个神经元的隐藏层，我们需要随机化一个3层矩阵，然后让矩阵的每个值和keep-prob去比较，则等于1的概率为0.8，等于0的概率为0.2(python中为true和false，但相乘时还是会看做0和1)</p>
<p>反向随机失活为了确保a的期望值不变，在最后会除以keep-prob把损失的值弥补回来，这样做在验证时会变得简单</p>
<p><img src="/img/Pastedimage20230905113044.png" alt="图片"></p>
<p>在测试阶段，我们不使用dropout，因为此时我们不希望测试结果是随机的。如果测试时用dropout，我们测试多次取平均的效果也差不多，不过计算效率很低。</p>
<p>在训练阶段除以keep-prob是为了保证即使在测试阶段不使用dropout，得到的结果预期也和训练的差不多。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.9%20%E5%BD%92%E4%B8%80%E5%8C%96%E8%BE%93%E5%85%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.9%20%E5%BD%92%E4%B8%80%E5%8C%96%E8%BE%93%E5%85%A5/" class="post-title-link" itemprop="url">1.9 归一化输入</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-26 00:00:00 / 修改时间：15:36:04" itemprop="dateCreated datePublished" datetime="2023-10-26T00:00:00+08:00">2023-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习2-改善深层神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>训练神经网络其中一个加速训练的方法就是归一化。</p>
<p>对一组数据，我们先将其中心化(x&#x3D;x-u)，再将其归一化(除以标准差)</p>
<p><img src="/img/Pastedimage20230905162442.png" alt="图片"></p>
<p>注意训练集和测试集需要使用同一个u和δ，防止不同。</p>
<p>如果我们不使用归一化，假设有一组输入(x1,x2)，x1的取值范围是0-1，x2的取值范围是0-1000，这会导致w的值范围相差过大，呈现出来就是椭圆形，在优化过程中我们就得用较小的步长去优化防止优化过度。归一化之后，x的值都在-1到1之间，w的值就是均匀的，我们可以用较大的步长去优化，帮助算法更快地运行</p>
<p><img src="/img/Pastedimage20230905163412.png" alt="图片"></p>
<p>当输入特征处在相似范围内时，使用归一化并不会有太大的帮助，然而执行归一化也不会产生什么危害。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.1%20Mini-batch%20%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.1%20Mini-batch%20%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/" class="post-title-link" itemprop="url">2.1 Mini-batch 梯度下降法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-26 00:00:00 / 修改时间：15:37:36" itemprop="dateCreated datePublished" datetime="2023-10-26T00:00:00+08:00">2023-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习2-改善深层神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在处理大数据时，我们动辄要处理上百万条数据。如果用正常的向量法来处理数据，则X矩阵大小为(nx,1000000)，实在是太大了。</p>
<p>因此我们用mini-batch梯度下降法，每次取1000个数据，将所有样本划分为1000份，分批次处理。这样每次处理的矩阵大小为(nx,1000)。</p>
<p>我们用大括号表示划分后的样本，X^{t}表示第t个大样本，包括1000个样例</p>
<p><img src="/img/Pastedimage20230912165155.png" alt="图片"></p>
<p>使用mini-batch梯度下降，对每一批样本我们都做了一次梯度下降，这样对整个数据集(假设有500万的数据，minibatch&#x3D;1000，即有5000个大样本)就做了5000次梯度下降。对比以前的方法，这样做的好处是仅仅一次数据集变量就做了5000次的梯度下降</p>
<p><img src="/img/Pastedimage20230912173220.png" alt="图片"></p>
<p>在训练巨大数据集时，mini-batch梯度下降法比普通的梯度下降法速度更快，所以人们更喜欢用mini-batch梯度下降法。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.10%20%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.10%20%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E9%97%AE%E9%A2%98/" class="post-title-link" itemprop="url">2.10 局部最优问题</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-26 00:00:00 / 修改时间：16:28:08" itemprop="dateCreated datePublished" datetime="2023-10-26T00:00:00+08:00">2023-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习2-改善深层神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>我们有时可能会担心梯度下降会收敛到局部最优点，而不是全局最优点，如图中的蓝色点位</p>
<p><img src="/img/Pastedimage20230914164137.png" alt="图片"></p>
<p>但事实上遇到这种情况的几率很小，比如你有20000个参数，遇到这样的点位意味着每个参数都同时在凹位或者凸位，这样的几率是(0.5)^20000</p>
<p><img src="/img/Pastedimage20230914164359.png" alt="图片"></p>
<p>绝大多数情况最优点都在鞍点上，即某个方向向上弯曲，另一个方向向下弯曲，在高维空间中，绝大多数都是这种情况</p>
<p><img src="/img/Pastedimage20230914164536.png" alt="图片"></p>
<p>即梯度为0的点绝大多数都不是局部最优点，更可能是鞍点。</p>
<p>鞍点没有局部最优的问题，但它有平稳段会减缓学习，平稳段是一个区域，其中的导数长时间接近于0</p>
<p><img src="/img/Pastedimage20230915100814.png" alt="图片"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.3%20%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/26/%E8%AF%BE%E7%A8%8B2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2.3%20%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87/" class="post-title-link" itemprop="url">2.3 指数加权平均</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-26 00:00:00 / 修改时间：15:49:24" itemprop="dateCreated datePublished" datetime="2023-10-26T00:00:00+08:00">2023-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习2-改善深层神经网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>假设我们有近几日的温度图，现在要算它们的平均温度</p>
<p><img src="/img/Pastedimage20230913153727.png" alt="图片"></p>
<p>假设初始值V_0&#x3D;0，V_t&#x3D;0.9V_t-1+0.1θ_t</p>
<p>其中Vt表示第t天前几天的温度加权平均值，θt表示当天的温度，则移动加权平均值如图</p>
<p><img src="/img/Pastedimage20230913161042.png" alt="图片"></p>
<p>其中0.9是权重参数β，用来表示是前1&#x2F;(1-β)天的平均值，β值越大，代表平均的天数越多</p>
<p><img src="/img/Pastedimage20230913161331.png" alt="图片"></p>
<p>图中红线为10天的平均值，黄线是2天的平均值，绿线是50天的平均值。可以看出，随着β值的升高，平均的天数越来越大，线也更加平滑，但同时线也越来越往右偏。这是因为β值升高，当天温度的权重就越来越小，温度的变化趋势也越来越滞后。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/13/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/">15</a><a class="page-number" href="/page/16/">16</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/15/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">GMRCCC</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
