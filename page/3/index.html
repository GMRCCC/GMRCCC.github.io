<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"gmrccc.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="GM兔的博客">
<meta property="og:type" content="website">
<meta property="og:title" content="GMR&#39;s Blog">
<meta property="og:url" content="http://gmrccc.com/page/3/index.html">
<meta property="og:site_name" content="GMR&#39;s Blog">
<meta property="og:description" content="GM兔的博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="GMRCCC">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://gmrccc.com/page/3/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/3/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>GMR's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">GMR's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="GMRCCC"
      src="/uploads/1.jpg">
  <p class="site-author-name" itemprop="name">GMRCCC</p>
  <div class="site-description" itemprop="description">GM兔的博客</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">158</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/GMRCCC" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;GMRCCC" rel="noopener me" target="_blank">GitHub</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/30/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/21%20%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%A5%97%E8%B7%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/30/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/21%20%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%A5%97%E8%B7%AF/" class="post-title-link" itemprop="url">21 完整的模型训练套路</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-10-30 00:00:00" itemprop="dateCreated datePublished" datetime="2023-10-30T00:00:00+08:00">2023-10-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-31 15:39:30" itemprop="dateModified" datetime="2023-10-31T15:39:30+08:00">2023-10-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" itemprop="url" rel="index"><span itemprop="name">PyTorch快速入门</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data = torchvision.datasets.CIFAR10(root=<span class="string">&quot;data&quot;</span>, train=<span class="literal">True</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)  </span><br><span class="line">test_data = torchvision.datasets.CIFAR10(root=<span class="string">&quot;data&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="查看数据集长度"><a href="#查看数据集长度" class="headerlink" title="查看数据集长度"></a>查看数据集长度</h3><p>这里我们用f格式化字符串来打印长度，还有很多其他的方法可以参考python语法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_data_size = <span class="built_in">len</span>(train_data)  </span><br><span class="line">test_data_size = <span class="built_in">len</span>(test_data)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练数据集的长度为：<span class="subst">&#123;train_data_size&#125;</span>&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试数据集的长度为：<span class="subst">&#123;test_data_size&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="搭建神经网络"><a href="#搭建神经网络" class="headerlink" title="搭建神经网络"></a>搭建神经网络</h3><p>还是搭建CIFAR10神经网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Tudui</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">        self.model = nn.Sequential(  </span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>,<span class="number">2</span>),  </span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),  </span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),  </span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),  </span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),  </span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),  </span><br><span class="line">            nn.Flatten(),  </span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">64</span>),  </span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">10</span>)  </span><br><span class="line">        )  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        x = self.model(x)  </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>一般神经网络会单独放在一个文件里，要用时再引入即可。</p>
<h3 id="验证神经网络"><a href="#验证神经网络" class="headerlink" title="验证神经网络"></a>验证神经网络</h3><p>我们一般用main来验证神经网络的准确性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    tudui = Tudui()  </span><br><span class="line">    <span class="built_in">input</span> = torch.ones(<span class="number">64</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)  </span><br><span class="line">    output = tudui(<span class="built_in">input</span>)  </span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">torch.Size([<span class="number">64</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<h3 id="创建网络模型"><a href="#创建网络模型" class="headerlink" title="创建网络模型"></a>创建网络模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tudui = Tudui()</span><br></pre></td></tr></table></figure>

<p>创建损失函数和优化器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss_fn = nn.CrossEntropyLoss()  </span><br><span class="line">learning_rate = <span class="number">1e-2</span>  </span><br><span class="line">optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>

<p>为了便于调整，我们一般把学习速率用一个单独的参数保存。</p>
<h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">total_train_step = <span class="number">0</span>  </span><br><span class="line">total_test_step = <span class="number">0</span>  </span><br><span class="line">epoch = <span class="number">10</span>  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;--------第<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>轮训练开始------------&quot;</span>)  </span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:  </span><br><span class="line">        imgs, targets = data  </span><br><span class="line">        out = tudui(imgs)  </span><br><span class="line">        loss = loss_fn(output, targets)  </span><br><span class="line">  </span><br><span class="line">        optimizer.zero_grad()  </span><br><span class="line">        loss.backward()  </span><br><span class="line">        optimizer.step()  </span><br><span class="line">        total_train_step += <span class="number">1</span>  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;训练次数:&#123;&#125;, Loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_train_step, loss.item()))</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">--------第<span class="number">1</span>轮训练开始------------</span><br><span class="line">训练次数:<span class="number">1</span>, Loss:<span class="number">2.305388927459717</span></span><br><span class="line">训练次数:<span class="number">2</span>, Loss:<span class="number">2.311274290084839</span></span><br><span class="line">训练次数:<span class="number">3</span>, Loss:<span class="number">2.3047678470611572</span></span><br><span class="line">训练次数:<span class="number">4</span>, Loss:<span class="number">2.29917311668396</span></span><br><span class="line">训练次数:<span class="number">5</span>, Loss:<span class="number">2.313053607940674</span></span><br><span class="line">训练次数:<span class="number">6</span>, Loss:<span class="number">2.305431842803955</span></span><br><span class="line">训练次数:<span class="number">7</span>, Loss:<span class="number">2.308323860168457</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>使用item函数取出的元素值精度更高，所以在求损失函数时一般用item()，item还会把tensor数据类型转化为一个真实的数字。</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">total_test_loss = <span class="number">0</span>  </span><br><span class="line"><span class="keyword">with</span> torch.no_grad():  </span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:  </span><br><span class="line">        imgs, targets = data  </span><br><span class="line">        outputs = tudui(imgs)  </span><br><span class="line">        loss = loss_fn(outputs, targets)  </span><br><span class="line">        total_test_loss += loss.item()  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_test_loss))</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">整体测试集上的loss:<span class="number">314.83741188049316</span></span><br></pre></td></tr></table></figure>

<p>在测试集上验证我们不需要梯度，因此使用with来跑循环且不设置优化器。</p>
<p>为了防止训练打印的结果过多，我们可以让其每100个打印一次，这样可以极大减少输出数据量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> total_train_step % <span class="number">100</span> ==<span class="number">0</span>  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;训练次数:&#123;&#125;, Loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_train_step, loss.item()))</span><br></pre></td></tr></table></figure>

<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><p>我们也可以用tensorboard对数据进行处理，为节省时间，我们将epoch设置为1.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line"><span class="keyword">import</span> torchvision  </span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> *  </span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn  </span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader  </span><br><span class="line">  </span><br><span class="line">train_data = torchvision.datasets.CIFAR10(root=<span class="string">&quot;data&quot;</span>, train=<span class="literal">True</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)  </span><br><span class="line">test_data = torchvision.datasets.CIFAR10(root=<span class="string">&quot;data&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)  </span><br><span class="line">  </span><br><span class="line">train_data_size = <span class="built_in">len</span>(train_data)  </span><br><span class="line">test_data_size = <span class="built_in">len</span>(test_data)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练数据集的长度为：<span class="subst">&#123;train_data_size&#125;</span>&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试数据集的长度为：<span class="subst">&#123;test_data_size&#125;</span>&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">train_dataloader = DataLoader(train_data, batch_size=<span class="number">64</span>)  </span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=<span class="number">64</span>)  </span><br><span class="line">  </span><br><span class="line">tudui = Tudui()  </span><br><span class="line">  </span><br><span class="line">loss_fn = nn.CrossEntropyLoss()  </span><br><span class="line">learning_rate = <span class="number">1e-2</span>  </span><br><span class="line">optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate)  </span><br><span class="line">  </span><br><span class="line">total_train_step = <span class="number">0</span>  </span><br><span class="line">total_test_step = <span class="number">0</span>  </span><br><span class="line">epoch = <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs_train&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;--------第<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>轮训练开始------------&quot;</span>)  </span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:  </span><br><span class="line">        imgs, targets = data  </span><br><span class="line">        outputs = tudui(imgs)  </span><br><span class="line">        loss = loss_fn(outputs, targets)  </span><br><span class="line">  </span><br><span class="line">        optimizer.zero_grad()  </span><br><span class="line">        loss.backward()  </span><br><span class="line">        optimizer.step()  </span><br><span class="line">        total_train_step += <span class="number">1</span>  </span><br><span class="line">        <span class="keyword">if</span> total_train_step % <span class="number">100</span> == <span class="number">0</span>:  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;训练次数:&#123;&#125;, Loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_train_step, loss.item()))  </span><br><span class="line">            writer.add_scalar(<span class="string">&quot;train_loss&quot;</span>, loss.item(), total_train_step)  </span><br><span class="line">    total_test_loss = <span class="number">0</span>  </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  </span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:  </span><br><span class="line">            imgs, targets = data  </span><br><span class="line">            outputs = tudui(imgs)  </span><br><span class="line">            loss = loss_fn(outputs, targets)  </span><br><span class="line">            total_test_loss += loss.item()  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;整体测试集上的loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_test_loss))  </span><br><span class="line">    writer.add_scalar(<span class="string">&quot;test_loss&quot;</span>, total_test_loss, total_test_step)  </span><br><span class="line">    total_test_step += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">writer.close()</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">训练数据集的长度为：<span class="number">50000</span></span><br><span class="line">测试数据集的长度为：<span class="number">10000</span></span><br><span class="line">--------第<span class="number">1</span>轮训练开始------------</span><br><span class="line">训练次数:<span class="number">100</span>, Loss:<span class="number">2.2900829315185547</span></span><br><span class="line">训练次数:<span class="number">200</span>, Loss:<span class="number">2.287980079650879</span></span><br><span class="line">训练次数:<span class="number">300</span>, Loss:<span class="number">2.267312526702881</span></span><br><span class="line">训练次数:<span class="number">400</span>, Loss:<span class="number">2.1998822689056396</span></span><br><span class="line">训练次数:<span class="number">500</span>, Loss:<span class="number">2.105910301208496</span></span><br><span class="line">训练次数:<span class="number">600</span>, Loss:<span class="number">2.014793634414673</span></span><br><span class="line">训练次数:<span class="number">700</span>, Loss:<span class="number">1.9981130361557007</span></span><br><span class="line">整体测试集上的loss:<span class="number">311.99298334121704</span></span><br></pre></td></tr></table></figure>

<p><img src="/img/Pastedimage20230801105325.png" alt="图片"><img src="/img/Pastedimage20230801105334.png" alt="图片"></p>
<p>可以看到随着步数的迭代，损失函数值在逐渐下降。</p>
<h3 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h3><p>我们可以把每一轮训练的模型都保存起来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(tudui, <span class="string">&quot;tudui_&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(i))</span><br></pre></td></tr></table></figure>

<h3 id="结果显示"><a href="#结果显示" class="headerlink" title="结果显示"></a>结果显示</h3><p>在目标检测或者语义分割问题中，我们可以直接用tensorboard来查看结果。</p>
<p>在上面代码的outputs变量，它输出的不是某一类的结果值，而是每个类的概率，像这样</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[-<span class="number">1.4025e+00</span>,  <span class="number">4.7173e-01</span>,  <span class="number">3.2860e-01</span>,  <span class="number">2.1276e-01</span>,  <span class="number">3.6439e-01</span>,</span><br><span class="line"><span class="number">3.1630e-01</span>,  <span class="number">5.3420e-01</span>,  <span class="number">4.1467e-01</span>, -<span class="number">1.3389e+00</span>, -<span class="number">2.9006e-01</span>]</span><br></pre></td></tr></table></figure>

<p>但是targets输出的是具体哪一个类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">targets:tensor([<span class="number">6</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">8</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">0</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<p>这里的batch_size &#x3D; 64，所以输出64个数据。</p>
<p>为了让outputs能和targets进行比较，pytorch提供了argmax方法，这个方法能够求出横向最大值所在的位置，转化之后，我们就可以将outputs和targets进行比较从而计算出正确率。</p>
<p><img src="/img/Pastedimage20230801112303.png" alt="图片"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line">outputs = torch.tensor([[<span class="number">0.1</span>, <span class="number">0.2</span>],[<span class="number">0.3</span>, <span class="number">0.4</span>]])  </span><br><span class="line"><span class="built_in">print</span>(outputs.argmax(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>argmax的参数为1代表是横向看，0代表是纵向看。</p>
<p>现在我们就能通过argmax来计算准确率了，我们先自己设一个target，和argmax后的outputs进行比较，将比较结果加起来除以总数即为准确率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">preds = outputs.argmax(<span class="number">1</span>)</span><br><span class="line">targets = torch.tensor(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(preds == targets)</span><br><span class="line"><span class="built_in">print</span>((preds == targets).<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">tensor([<span class="literal">False</span>,  <span class="literal">True</span>])</span><br><span class="line">tensor(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>现在我们就可以对整体整体代码进行优化了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">total_accuracy = <span class="number">0</span>  </span><br><span class="line"><span class="keyword">with</span> torch.no_grad():  </span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:  </span><br><span class="line">        ...</span><br><span class="line">        accuracy = (outputs.argmax(<span class="number">1</span>) == targets).<span class="built_in">sum</span>()  </span><br><span class="line">        total_accuracy += accuracy  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;整体测试集上的正确率:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_accuracy/test_data_size))  </span><br><span class="line">...</span><br><span class="line">writer.add_scalar(<span class="string">&quot;test_accuracy&quot;</span>, total_accuracy/test_data_size, total_test_step)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">整体测试集上的正确率:<span class="number">0.2734000086784363</span></span><br></pre></td></tr></table></figure>

<h3 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h3><p>在训练和测试开始前，有的代码会在前面加上这样一句</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tudui.train()</span><br><span class="line"><span class="meta">... </span><span class="comment"># 训练开始</span></span><br><span class="line">tudui.<span class="built_in">eval</span>()</span><br><span class="line"><span class="meta">... </span><span class="comment"># 测试开始</span></span><br></pre></td></tr></table></figure>

<p>这两句话并不是必要的，它们只对部分层有作用，官方说明是这样的</p>
<p>This has any effect only on certain modules. See documentations of particular modules for details of their behaviors in training&#x2F;evaluation mode, if they are affected, e.g. <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout"><code>Dropout</code></a>, <code>BatchNorm</code>, etc.</p>
<p>当我们的网络模型中有dropout或者batchnorm等层时，我们可以调用它。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/30/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/20%20%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%AF%BB%E5%8F%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/30/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/20%20%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%AF%BB%E5%8F%96/" class="post-title-link" itemprop="url">20 网络模型的保存与读取</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-10-30 00:00:00" itemprop="dateCreated datePublished" datetime="2023-10-30T00:00:00+08:00">2023-10-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-31 15:36:38" itemprop="dateModified" datetime="2023-10-31T15:36:38+08:00">2023-10-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" itemprop="url" rel="index"><span itemprop="name">PyTorch快速入门</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="方法1"><a href="#方法1" class="headerlink" title="方法1"></a>方法1</h3><p>直接把模型保存成一个文件，然后读取，保存的是模型结构+模型参数。</p>
<p>保存</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)  </span><br><span class="line">torch.save(vgg16, <span class="string">&quot;文件路径/vgg16_method1.pth&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>读取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = torch.load(<span class="string">&quot;vgg16_method1.pth&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">vgg16_false.classifier[<span class="number">6</span>] = nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)  </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(vgg16_false)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">VGG(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    ...</span><br><span class="line">    (<span class="number">30</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Linear(in_features=<span class="number">25088</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    ...</span><br><span class="line">    (<span class="number">6</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">1000</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这种方法有个陷阱，比如我们自己创一个模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Tudui</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        x = self.conv1(x)  </span><br><span class="line">        <span class="keyword">return</span> x  </span><br><span class="line">  </span><br><span class="line">tudui = Tudui()  </span><br><span class="line">torch.save(tudui, <span class="string">&quot;tudui.method1.pth&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>然后到其他文件取加载</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = torch.load(<span class="string">&quot;tudui.method1.pth&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">报错，Can<span class="string">&#x27;t get attribute &#x27;</span>Tudui<span class="string">&#x27; on &lt;module &#x27;</span>__main__<span class="string">&#x27; from &#x27;</span>C:\\Home\\PycharmProjects\\pythonProject\\model_pretrained.py<span class="string">&#x27;&gt;</span></span><br></pre></td></tr></table></figure>

<p>可以发现报错了，无法确定土堆的网络模型，所以其他文件也需要把模型移过来，或者把模型保存的文件导入也行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Tudui</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        x = self.conv1(x)  </span><br><span class="line">        <span class="keyword">return</span> x  </span><br><span class="line">model = torch.load(<span class="string">&quot;tudui.method1.pth&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">Tudui(</span><br><span class="line">  (conv1): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="方法2"><a href="#方法2" class="headerlink" title="方法2"></a>方法2</h3><p>用字典保存VGG16的状态即参数，然后读取，只保存了模型参数。(官方推荐，因为保存空间更小)</p>
<p> 保存</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(vgg16.state_dict(),<span class="string">&quot;vgg16_method1.pth&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>读取</p>
<p>若直接读取，则读取出来的是字典形式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = torch.load(<span class="string">&quot;vgg16_method2.pth&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">字典，太长了就不放了</span><br></pre></td></tr></table></figure>

<p>我们需要新建一个网络结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)  </span><br><span class="line">vgg16.load_state_dict(torch.load(<span class="string">&quot;vgg16_method1.pth&quot;</span>))  </span><br><span class="line"><span class="built_in">print</span>(vgg16)</span><br></pre></td></tr></table></figure>






      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/30/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/23%20%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81%E5%A5%97%E8%B7%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/30/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/23%20%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81%E5%A5%97%E8%B7%AF/" class="post-title-link" itemprop="url">23 完整的模型验证套路</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-10-30 00:00:00" itemprop="dateCreated datePublished" datetime="2023-10-30T00:00:00+08:00">2023-10-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-31 15:48:24" itemprop="dateModified" datetime="2023-10-31T15:48:24+08:00">2023-10-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" itemprop="url" rel="index"><span itemprop="name">PyTorch快速入门</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>我们随便打开一个github上的pytorch项目，比如<a target="_blank" rel="noopener" href="https://github.com/junyanz">junyanz</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">pytorch-CycleGAN-and-pix2pix</a></strong></p>
<p>可以看到里面有训练和验证的py文件</p>
<p><img src="/img/Pastedimage20230801170811.png" alt="图片"></p>
<p>我们新建一个test.py文件，导入一张dog.png用image接受，注意用convert将image转为3通道。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">image_path = <span class="string">&quot;dog.png&quot;</span>  </span><br><span class="line">image = Image.<span class="built_in">open</span>(image_path)  </span><br><span class="line"><span class="built_in">print</span>(image)  </span><br><span class="line">image = image.convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">输出：</span><br><span class="line">&lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=473x266 at <span class="number">0x1D52159B400</span>&gt;</span><br></pre></td></tr></table></figure>

<p>此时的image是PIL格式，可以用resize函数进行裁剪，再转为tensor格式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tranform = torchvision.transforms.Compose(  </span><br><span class="line">    [torchvision.transforms.Resize([<span class="number">32</span>, <span class="number">32</span>]),  </span><br><span class="line">     torchvision.transforms.ToTensor()]  </span><br><span class="line">)  </span><br><span class="line">image = tranform(image)  </span><br><span class="line"><span class="built_in">print</span>(image.shape)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>])</span><br></pre></td></tr></table></figure>

<p>导入神经网络，这里采用提过的方法二</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Tudui</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>().__init__()  </span><br><span class="line">        self.model = nn.Sequential(  </span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>,<span class="number">2</span>),  </span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),  </span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),  </span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),  </span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),  </span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),  </span><br><span class="line">            nn.Flatten(),  </span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">64</span>),  </span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">10</span>)  </span><br><span class="line">        )  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        x = self.model(x)  </span><br><span class="line">        <span class="keyword">return</span> x  </span><br><span class="line">  </span><br><span class="line">model = torch.load(<span class="string">&quot;tudui_0.pth&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>然后我们尝试将图片输入神经网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output = model(image)  </span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">报错</span><br></pre></td></tr></table></figure>

<p>发现报错了，这是因为图片默认是3维的，但输入神经网络的图片必须是4维的，即需要指定batch_size。</p>
<p>我们将image重新reshape一下，再写上with语句来节约性能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">image = torch.reshape(image, (<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))  </span><br><span class="line">model.<span class="built_in">eval</span>()  </span><br><span class="line"><span class="keyword">with</span> torch.no_grad():  </span><br><span class="line">    output = model(image)  </span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<p>还是报错，这是因为模型是用gpu训练的，但image是cpu的，它们的参数写的不一样，数据无法导入，因此我们需要再对image进行一次转化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">image = image.cuda()</span><br><span class="line">输出：</span><br><span class="line">tensor([[-<span class="number">3.8505</span>, -<span class="number">1.2259</span>,  <span class="number">1.0707</span>,  <span class="number">0.8424</span>,  <span class="number">2.0482</span>,  <span class="number">0.9754</span>,  <span class="number">3.0550</span>,  <span class="number">1.4181</span>,</span><br><span class="line">         -<span class="number">4.7376</span>, -<span class="number">1.2660</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>我们也可以用map_location将模型由gpu转为cpu</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = torch.load(<span class="string">&quot;tudui_0.pth&quot;</span>, map_location=torch.device(<span class="string">&#x27;cpu&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>用argmax进行类别预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(output.argmax(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">输出:</span><br><span class="line">tensor([<span class="number">6</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/30/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/22%20%E5%88%A9%E7%94%A8GPU%E8%AE%AD%E7%BB%83/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/30/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/22%20%E5%88%A9%E7%94%A8GPU%E8%AE%AD%E7%BB%83/" class="post-title-link" itemprop="url">22 利用GPU训练</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-10-30 00:00:00" itemprop="dateCreated datePublished" datetime="2023-10-30T00:00:00+08:00">2023-10-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-31 15:46:23" itemprop="dateModified" datetime="2023-10-31T15:46:23+08:00">2023-10-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/PyTorch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" itemprop="url" rel="index"><span itemprop="name">PyTorch快速入门</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><p>网络模型、损失函数和数据都可以使用cuda方法，注意优化器不行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">tudui = tudui.cuda()</span><br><span class="line">loss_fn = loss_fn.cuda()</span><br><span class="line">...</span><br><span class="line">loss_fn = loss_fn.cuda()</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>这样的写法不太规范，我们可以加一个if判断</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">	tudui = tudui.cuda()</span><br></pre></td></tr></table></figure>

<p>我们记录下运行的时间，看一下耗时差距</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">start_time = time.time()</span><br><span class="line">...</span><br><span class="line">end_time = time.time()</span><br><span class="line"><span class="built_in">print</span>(end_time - start_time)</span><br></pre></td></tr></table></figure>

<p>会发现速度有了很大的提高(这里懒得再重新跑了，知道就行)。</p>
<p>我们也可以在Google colab网用GPU跑，注意需要科学上网。</p>
<p>在右上角修改处的笔记本设置可以开启GPU，Google colab每周有免费的GPU使用时间。</p>
<p><img src="/img/Pastedimage20230801160015.png" alt="图片"></p>
<p>然后运行我们的代码</p>
<p><img src="/img/Pastedimage20230801160527.png" alt="图片"></p>
<p>可以看到跑的速度非常快，平均1秒就可以训练100次。</p>
<p>在Google colab中，我们可以在代码前面加！表示在terminal中运行，比如我们可以看一下配置</p>
<p><img src="/img/Pastedimage20230801160732.png" alt="图片"></p>
<p>70w的特斯拉T4显卡，非常的强。如果要跑一些小项目的话，完全可以在Google colab上跑。</p>
<h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><p>我们可以用device来指定显卡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">...</span><br><span class="line">tudui = tudui.to(device)</span><br><span class="line">loss_fn = loss_fn.to(device)</span><br><span class="line">...</span><br><span class="line">imgs = imgs.to(device)  </span><br><span class="line">targets = targets.to(device)</span><br></pre></td></tr></table></figure>

<p><img src="/img/Pastedimage20230801162556.png" alt="图片"></p>
<p>可以看到速度非常快，说明启用了cuda。</p>
<p>另外，有时候其他代码上网络模型和损失函数都没有额外赋值，这其实不是必要的，只有图片和数据需要额外赋值。</p>
<p>我们也可以用语法糖来简化代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AFML%E7%AD%96%E7%95%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AFML%E7%AD%96%E7%95%A5/" class="post-title-link" itemprop="url">1.1 为什么是ML策略</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：09:23:54" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习3-机器学习（ML）策略</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>假设你在训练一个识别猫的模型，训练出来的模型正确率有90%。</p>
<p><img src="/img/Pastedimage20230920150053.png" alt="图片"></p>
<p>现在你希望能够提高模型识别的正确率，但方法有很多，你希望能判断出哪种方法是靠谱的，以免白白浪费时间</p>
<p><img src="/img/Pastedimage20230920150121.png" alt="图片"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.10%20%E7%90%86%E8%A7%A3%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.10%20%E7%90%86%E8%A7%A3%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B0/" class="post-title-link" itemprop="url">1.10 理解人的表现</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：10:08:30" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习3-机器学习（ML）策略</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>我们知道贝叶斯错误率是理论上最低的错误率，因此如果我们要用人类的错误率来近似贝叶斯错误率，我们应该使用最低值(即使这个最低值可能是由一个团队讨论后的结果)</p>
<p><img src="/img/Pastedimage20230922112917.png" alt="图片"></p>
<p>但如果只是为了应用或者发表论文，只要超过传统医生的表现就有一定的部署价值了。</p>
<p>当偏差和方差都很大时，我们很容易就能看出应该训练来减少偏差，当方差很大而偏差很小时我们也清楚应该正则化来减少方差，这也是当训练效果不及人时训练速度快的原因，因为可以借助现有的工具调整。</p>
<p>当偏差和方差都很小时，特别是当你的偏差很接近人能达到的效果时，你就不清楚此时的偏差距离贝叶斯偏差到底还差多少，也就不确定是否应该继续改善你的训练集。因此，当你的模型训练效果已经很好时，想继续改进往往比较困难</p>
<p><img src="/img/Pastedimage20230922151115.png" alt="图片"></p>
<p>所以在训练模型时，有时候我们最好不要设置贝叶斯误差为0，可以以人类的识别效果近似贝叶斯误差来对模型进行训练，这在模型训练初期可以帮助你更好的做决策以避免无用功</p>
<p><img src="/img/Pastedimage20230922153236.png" alt="图片"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.11%20%E8%B6%85%E8%BF%87%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.11%20%E8%B6%85%E8%BF%87%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B0/" class="post-title-link" itemprop="url">1.11 超过人的表现</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：10:10:41" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习3-机器学习（ML）策略</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>当你的训练集表现超过人时，可避免误差就无法计算，你也无法判断是否该继续优化你的训练集，如果要继续优化，也很难确定优化的方向</p>
<p><img src="/img/Pastedimage20230925161251.png" alt="图片"></p>
<p>但模型在很多地方已经超过了人的表现了，比如根据偏好推荐广告，贷款申请是否许可等等，在结构化数据领域，由于计算机能看到远比人多得多的数据，表现会比人类水平要好</p>
<p><img src="/img/Pastedimage20230925161802.png" alt="图片"></p>
<p>相比于结构化数据分析，人类更擅长做自然感知方面的事情，因此在自然感觉方面计算机很难超过人类，但在语音识别、计算机视觉中的某些领域，计算机的表现实际上也可以超过人类了。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.12%20%E6%94%B9%E5%96%84%E4%BD%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.12%20%E6%94%B9%E5%96%84%E4%BD%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B0/" class="post-title-link" itemprop="url">1.12 改善你模型的表现</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：10:12:58" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习3-机器学习（ML）策略</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在训练模型时，你往往会有两个期望，一个是期望训练偏差尽可能小，一个是期望在测试&#x2F;开发集上也能做的很好，也就是偏差和方差尽可能低</p>
<p><img src="/img/Pastedimage20230925162716.png" alt="图片"></p>
<p>根据正交化的精神，我们分别有不同的方法去降低可避免偏差(比如训练更大的网络或者训练更久)和降低方差(比如正则化或者收集更多的训练数据)。</p>
<p><img src="/img/Pastedimage20230925163422.png" alt="图片"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.2%20%E6%AD%A3%E4%BA%A4%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.2%20%E6%AD%A3%E4%BA%A4%E5%8C%96/" class="post-title-link" itemprop="url">1.2 正交化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：09:29:27" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习3-机器学习（ML）策略</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>假设你有一台电视，它有很多按钮，分别用来调整不同的性质(长、宽、位置、角度等等)。</p>
<p>如果有这样一个按钮，它能同时调整这些所有的性质，那么我们几乎不可能通过这个按钮将画面调到我们想要的地步。</p>
<p>在这个例子中，正交化就是指设计的旋钮每一个都只调整一个性质。</p>
<p><img src="/img/Pastedimage20230920151840.png" alt="图片"></p>
<p>车的例子也类似，如果有按钮可以同时控制车的方向和速度，即使按钮有两个，我们也很难让车变成我们想要的状态，但如果两个按钮分别控制方向和速度，那么这件事就会简单很多</p>
<p><img src="/img/Pastedimage20230920151954.png" alt="图片"></p>
<p>训练网络的过程也类似，我们希望模型在训练集、验证集、测试集和实际生活中的表现都很不错。</p>
<p>如果训练集表现不佳，我们可以用换更大的网络、adam优化算法等方式改善；如果验证集效果不好，可以用正则化方法来改善；如果测试集效果不好，说明验证集过拟合了，可以换更大的验证集；而如果在实际生活中效果不好，说明我们评估的方法可能有问题，需要换一个损失函数或者换一个验证集</p>
<p><img src="/img/Pastedimage20230920153408.png" alt="图片"></p>
<p>这个角度考虑的话不建议使用early stopping，因为它在改善验证集性能的同时，会影响训练集的效果，没有做到正交化。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://gmrccc.com/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.3%20%E5%8D%95%E4%B8%80%E6%95%B0%E5%AD%97%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="GMRCCC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GMR's Blog">
      <meta itemprop="description" content="GM兔的博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | GMR's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/27/%E8%AF%BE%E7%A8%8B3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/1.3%20%E5%8D%95%E4%B8%80%E6%95%B0%E5%AD%97%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/" class="post-title-link" itemprop="url">1.3 单一数字评估指标</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2023-10-27 00:00:00 / 修改时间：09:32:18" itemprop="dateCreated datePublished" datetime="2023-10-27T00:00:00+08:00">2023-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/" itemprop="url" rel="index"><span itemprop="name">吴恩达深度学习3-机器学习（ML）策略</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>如果我们能用单个数字来评估分类器，那么我们评估的速度将会非常快。</p>
<p>比如，我们需要去识别猫的图片，我们需要知道识别的精度和召回率，但通过这两个指标去评判哪个分类器更好非常困难(可能一个精度高而另一个召回率高)，因此在实际使用中我们通常会通过F1 Score去帮助我们快速择优，加速算法的迭代</p>
<p><img src="/img/Pastedimage20230920161314.png" alt="图片"></p>
<p>另一个例子是判断不同地区的人识别的错误率，我们通常会取平均值作为单一数字指标去判断分类器的优劣</p>
<p><img src="/img/Pastedimage20230920161642.png" alt="图片"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">GMRCCC</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
